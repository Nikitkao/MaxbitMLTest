# MaxbitMLTest

Проект по обучению модели для предсказания здоровья дерева в Нью Йорке по набору данных. Для воспроизведения обучения модели открыть файл torch.ipynb в jupiter notebook. Для проверки модели на данных которые она не видела открыть файл Inference.ipynb . Для запуска сервера открыть консоль в папке с проектом и выполнить команду uvicorn app:app --reload . cUrl для постамана: 

curl --location 'http://127.0.0.1:8000/predict' \
--header 'Content-Type: application/json' \
--data '{
    "tree_dbh": 2,
    "spc_common": "black walnut",
    "spc_latin": "Juglans nigra",
    "postcode": 11217,
    "borough": "Brooklyn",
    "zip_city": "Brooklyn",
    "steward": "None",
    "guards": "None",
    "sidewalk": "NoDamage",
    "user_type": "Volunteer",
    "root_stone": "No",
    "root_grate": "No",
    "root_other": "Yes",
    "trunk_wire": "No",
    "trnk_light": "No",
    "trnk_other": "No",
    "brch_light": "No",
    "brch_shoe": "No",
    "brch_other": "No",
    "curb_loc": "OnCurb"
  }'

Процесс принятия решений: открыл сайт источником данных, там было описание столбцов (параметров), ознакомился, прикинул примерно какие данные мне будут не нужны. Открыл датафрейм, посмотрел выбросы и отсутствие данных. Сразу удалил те строчки где нету целевой переменной, потом дополнил строчки в которых можно было заменить NaN на None например, потом дополнил строчки которые можно дополнить на основе других параметров, в целом можно было более тщательно подойти и использовать геоданные дял заполнения, если оставались доли процентов строк в которых не было значений просто удалял их, хотя в конце подумал что там могли быть данные определенного типа целевого столбца которых было меньше. Проверил баланс целевого столбца, он был плох, 80% критерия Good. Модель слабо определяла что то кроме Good, я попробовал  использование взвешенной функции потерь (criterion), это улучшило ситуацию, но не сильно, попробовал SMOTE, это дало прирост в точности значительный для всех классов кроме Good :) Также для кодирования данных использовал LabelEncoding т к данные категориальные (кроме диаметра ствола) + использовал эмбеденги потому что категорий было много. Для оценки модели использовал F1-score, Precision-Recall . P.S сначала почему то не обратил внимание что нужно с пайторч работать, сделал с xgb. Думаю что можно было сделать аккуратнее и поподбирать еще гиперпараметры, но я сказал что сделаю за 2 дня и времени уже нету )


Выбор архитектуры модели был обусловлен несколькими ключевыми факторами, которые учитывают особенности ваших данных и задачи. Давайте разберем, почему была выбрана именно эта архитектура, и как она соответствует характеристикам вашего набора данных.

1. Характеристики данных
Объем данных: 652152 строк и 28 столбцов. Это достаточно большой объем данных, что позволяет использовать более сложные модели, такие как нейронные сети.

Типы данных:

Числовые признаки: Только один числовой признак (tree_dbh), который описывает диаметр ствола дерева.

Категориальные признаки: Большинство признаков являются категориальными (например, spc_latin, spc_common, borough, postcode и т.д.). Эти признаки имеют разное количество уникальных значений (от 2 до 1314).

Целевая переменная: health — категориальный признак с тремя классами ("Good", "Fair", "Poor"). Это задача многоклассовой классификации.

Пропущенные значения: В данных отсутствуют пропущенные значения, что упрощает предобработку.

2. Почему выбрана архитектура с эмбеддингами и полносвязными слоями?
Категориальные признаки
Категориальные признаки имеют разное количество уникальных значений (от 2 до 1314). Для их эффективного использования в нейронных сетях применяются эмбеддинги (embeddings). Эмбеддинги преобразуют категориальные значения в плотные векторы фиксированной длины, что позволяет модели лучше улавливать семантические связи между категориями.

Например:

Признак borough (5 уникальных значений) может быть закодирован в 5-мерный вектор.

Признак spc_latin (132 уникальных значения) может быть закодирован в 20-мерный вектор.

Эмбеддинги позволяют модели учить представления категориальных признаков, что особенно полезно для признаков с большим количеством уникальных значений (например, census tract с 1314 уникальными значениями).

Числовой признак
В данных только один числовой признак (tree_dbh). Он напрямую подается на вход модели без дополнительной обработки.

Полносвязные слои
После преобразования категориальных признаков в эмбеддинги и объединения их с числовым признаком, данные подаются на полносвязные слои (fully connected layers). Эти слои позволяют модели учить сложные нелинейные зависимости между признаками.

Использование нескольких полносвязных слоев с активацией ReLU и dropout помогает избежать переобучения и улучшить обобщающую способность модели.

Выходной слой
Выходной слой имеет размерность, равную количеству классов (3), и использует функцию активации softmax для многоклассовой классификации.

3. Преимущества выбранной архитектуры
Гибкость: Модель может эффективно работать с данными, где большинство признаков являются категориальными.

Масштабируемость: Эмбеддинги позволяют обрабатывать категориальные признаки с большим количеством уникальных значений.

Интерпретируемость: Эмбеддинги могут быть визуализированы (например, с помощью t-SNE или PCA), чтобы понять, как модель интерпретирует категориальные признаки.

Простота: Архитектура проста в реализации и хорошо работает на задачах классификации с табличными данными.

4. Альтернативные подходы и почему они не были выбраны
Деревья решений и ансамбли (Random Forest, XGBoost, LightGBM):

Эти методы хорошо работают с табличными данными, но они менее эффективны для категориальных признаков с большим количеством уникальных значений (например, census tract с 1314 уникальными значениями).

Они также не позволяют легко использовать эмбеддинги для категориальных признаков.

Линейные модели (логистическая регрессия):

Линейные модели плохо справляются с нелинейными зависимостями и категориальными признаками с большим количеством уникальных значений.

Сверточные нейронные сети (CNN):

CNN обычно используются для обработки изображений или текстов, а не для табличных данных.

Рекуррентные нейронные сети (RNN):

RNN предназначены для последовательностей (например, временных рядов или текстов), что не подходит для вашей задачи.

5. Как архитектура соответствует данным
Категориальные признаки: Эмбеддинги позволяют эффективно обрабатывать категориальные признаки с разным количеством уникальных значений.

Числовой признак: Единственный числовой признак (tree_dbh) напрямую подается на вход модели.

Целевая переменная: Выходной слой с тремя нейронами и функцией softmax идеально подходит для задачи классификации с тремя классами.

Балансировка данных: Использование SMOTE для балансировки классов помогает улучшить качество модели, особенно если классы несбалансированы.

6. Оценка качества модели
Для оценки качества модели можно использовать метрики, такие как точность (accuracy), F1-score, матрица ошибок (confusion matrix).

Если классы несбалансированы, важно обратить внимание на F1-score для каждого класса.

Также можно визуализировать ROC-кривую и AUC-ROC для оценки качества классификации.

Итог
Выбранная архитектура (нейронная сеть с эмбеддингами и полносвязными слоями) хорошо подходит для ваших данных, так как:

Она эффективно обрабатывает категориальные признаки с большим количеством уникальных значений.

Она позволяет модели учить сложные нелинейные зависимости между признаками.

Она проста в реализации и масштабируема для больших объемов данных.


